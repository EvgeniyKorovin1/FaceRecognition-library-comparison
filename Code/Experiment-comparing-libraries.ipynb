{"cells":[{"cell_type":"markdown","metadata":{"id":"a-UK2pX9MVNa"},"source":["# **Note on using the program:**\n","*   Для удобства пользования программа разбита на блоки, каждый из которых выполняет свой набор задач;\n","*   Не все блоки программы являются обязательными к запуску для корректной работы программы;\n","*   Часть блоков могут являться взаимоисключающими (выполнять одну и туже задачу разными способами) или не быть важными для непосредственного запуска при каждом использовании программы у таких блоков возле номера находятся пометки \"(alternative)\" и \"(optional)\" соответственно;\n",">**Для безопасного и правильного использования программы - просматривайте описания для блоков перед их запуском.**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2P5hwjKFIOuH"},"source":["**block 1:**\n","Подключение необходимых для работы программы библиотек"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33968,"status":"ok","timestamp":1712408013701,"user":{"displayName":"Евгений Коровин","userId":"16571264909826974855"},"user_tz":-180},"id":"ml5W_Q7gxiA4","outputId":"e1de3c34-c419-4653-91c0-9fbe27fa1d04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: deepface in /usr/local/lib/python3.10/dist-packages (0.0.89)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.25.2)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.0.3)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.7.3)\n","Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.2)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (9.4.0)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.8.0.76)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n","Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (0.1.1)\n","Requirement already satisfied: retina-face>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (0.0.16)\n","Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (0.6.0)\n","Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (21.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.4.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.0.2)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.13.3)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.12.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (24.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (67.7.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.10.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.62.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.43.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.5)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.7.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.2.2)\n","Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.17.1)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Requirement already satisfied: insightface in /usr/local/lib/python3.10/dist-packages (0.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.25.2)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from insightface) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from insightface) (4.66.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from insightface) (2.31.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from insightface) (3.7.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from insightface) (9.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.11.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from insightface) (1.2.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from insightface) (0.19.3)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from insightface) (3.0.10)\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from insightface) (1.3.1)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from insightface) (3.10.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (6.0.1)\n","Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.0.4)\n","Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (4.9.0.80)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (3.2.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2024.2.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (1.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (24.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (4.50.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (2.8.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->insightface) (3.20.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface) (0.2.13)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations->insightface) (4.10.0)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.3)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}],"source":["!pip install deepface\n","!pip install onnxruntime\n","!pip install insightface\n","!pip install gdown\n","\n","import gdown # Библиотека, что позволяет быстро получить доступ к данным хранимым на google grive\n","import insightface\n","import pandas as pd # Библиотека для работы с csv файлом\n","import numpy as np\n","from insightface.app import FaceAnalysis # Библиотека для работы с лицами\n","from deepface import DeepFace # Библиотека для работы с лицами\n","import zipfile # Дополнение для работы с архивом фотографий\n","import shutil # Дополнение для перемещения файлов\n","import json\n","import cv2 # Дополнение для работы с видео-файлом\n","import os # Дополнение для создания папок"]},{"cell_type":"markdown","metadata":{"id":"74Iiv01-fxyX"},"source":["**block 1.1 (optional):**\n","Дополнение для запуска из google kolab (позволяет видеть изображения - не обязательно)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZUBP3HKgA9b"},"outputs":[],"source":["from google.colab.patches import cv2_imshow # нужно при запуске из гугл колаб функции imshow"]},{"cell_type":"markdown","metadata":{"id":"gQ6x0wEwWRst"},"source":["#block 2 and block 3:\n","\n","> **Для дальнейшего использования программы необходимо добавить ссылки на днные по описанным ниже правилам, данные исходного эксперимента не являются публичными, поэтому недоступны для тестового запуска.**\n","\n","block 2 и block 3 являются взаимозаменяемыми и реализуют загрузку файлов (архив с фотографиями, информация о людях с фотографий, видеозаписи для поиска)в среду выполнения, разница в том, что:\n","\n","*   block 2 выполняет задачу используя библиотеку gdown, преназначенную для загрузки файлов с гугл диска, но не способную загружать их из других источников;\n","*   Block 3 выполняет задачу используя urllib.request, что позволяет загружать данные из любых свободных источников в интернете, но могут возникать сложность при загрузки больших файлов (более 500 Мб).\n","\n","> **В данном решении рекомендуется использовать block 2.**\n","\n","**Примечание:** для использования файлов с гугл диска нужно изменить формат ссылки с\n","https://drive.google.com/file/d/THE_LINK_TO_YOUR_FILE/view?usp=drive_link\n","на\n","https://docs.google.com/uc?id=THE_LINK_TO_YOUR_FILE"]},{"cell_type":"markdown","metadata":{"id":"aiBEbTSZI38k"},"source":["**block 2 (alternative):**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rnMR2VnzdkO8"},"outputs":[],"source":["files_url = {\n","    \"photo_staff.zip\" : \"\" # Архив исходных фото\n","    ,\"emb_staff_dict.json\" : \"\" # (не обязательно) загрузка файла с эмбедингами пригодных изображений - создается в Block 6 и может использоваться повторно\n","    ,\"names.csv\" : \"\" # Информация с именами, для идентификации вида: название фото - ФИО человека на фото\n","    ,\"video1.mp4\": \"\" # Первая видео-запись\n","    ,\"video2.mp4\": \"\" # Вторая видео-запись\n","    ,\"video3.mp4\": \"\" # Третья видео-запись\n","}\n","\n","for file in files_url:\n","  gdown.download(files_url[file], file, quiet=False)\n","\n","original_zip = zipfile.ZipFile('/content/photo_staff.zip')\n","original_zip.extractall('/content')\n","original_zip.close()"]},{"cell_type":"markdown","metadata":{"id":"kWB7l6BUTv2Q"},"source":["**block 3 (alternative):**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4k5DTySSx4NW"},"outputs":[],"source":["import urllib.request # Дополнение для загрузки необходимых данных\n","\n","files_url = {\n","    \"photo_staff.zip\" : \"\" # Архив исходных фото\n","    ,\"emb_staff_dict.json\" : \"\" # (не обязательно) загрузка файла с эмбедингами пригодных изображений - создается в Block 6 и может использоваться повторно\n","    ,\"names.csv\" : \"\" # Информация с именами, для идентификации вида: название фото - ФИО человека на фото\n","    ,\"video1.mp4\": \"\" # Первая видео-запись\n","    ,\"video2.mp4\": \"\" # Вторая видео-запись\n","    ,\"video3.mp4\": \"\" # Третья видео-запись\n","}\n","\n","for file in files_url:\n","     urllib.request.urlretrieve(files_url[file], file)\n","\n","original_zip = zipfile.ZipFile('/content/photo_staff.zip')\n","original_zip.extractall('/content')\n","original_zip.close()\n"]},{"cell_type":"markdown","source":["#block 4, block 5 and block 6:\n","В процессе разработки и оптимизации решения поставленной задачи, а именно, решая задачу верификации,  поскольку исходное множество лиц для поиска на видео велико - рассматривалась возможность сократить или видоизменить представление данного множества с целью снизить количесвто операций при верификации.\n","\n","Наиболее очевидным и рациональным из подходов, применимых к данной задаче, с целью сокрщения количества проверок на одно фото был вариант разбиения исходного списка фотографий на несколько более малых, по половому признаку.\n","\n","Собственно, в block 5 and block 6 представлены варианты программ, выполняющих данную задачу.\n","*   block 5 выполняет задачу используя библиотеку deepface;\n","*   Block 6 выполняет задачу используя insightface.\n","\n","Оценивая результаты, полученные посредством выполнения данных программ, был выведен ряд наблюдений:\n","* Таковым является наличие ошибок, причем различных, которыми могут быть как ненахождение лица на фото, так и неверная трактовка пола, что особенно заметно при анализе лиц старшей возрастной группы;\n","* Дополнением к этому является наличие некачественных данных загруженных самими пользователями: встречаются фотографии, на которых нет лиц вовсе или фото нескольких человек, что с точки зрения решаемой задачи могло бы помешать идентификации этих людей. В очень редких случаях (1) фото оказывается нечитаемым вовсе;\n","* Исходя из замеченных выше деталей приходим к выводу о низкой эффективности применения данного подхода, поскольку при использовании любой из библиотек точность прогноза не превышает значение 80%, то есть используя это звено мы добавляем дополнительную не всегда работающую точно проверку, тем самым приводя к росты издержек, который может выражаться в необходимости дополнительных циклов верификации или потере потенциальных лиц при поиске.\n","\n","Однако результаты проделанной работы могут быть использованы в других целях:\n","* В рамках разработки программы были получены возможность ознакомления и оценки качества используемых в ней библиотек. Решение на основе билиотеки deepface может похвастаться простатой внедрения, при работе с ним вы рассматриваете всего три случая: определен мужской пол, определен женский пол, произошла ошибка (ValueError). Что хорошо для новичка в данной сфере с одной стороны, но является не лучшим результатом для более квалифицированного специалиста, так как скрывает все возможные причины неполучения результата за одной ошибкой и не дает возможность увидеть ее причины глубже, что может быть критично, ведь неопознынный набор превысил 10% фотографий.\n","* Библиотека insightface в этоже время повышает уровень требований к ее пользвателю, но и дает больше возможностей, первым, что хочется отметить это лучшую способноть к распознаванию, количество неопознанных фото снизилось до 2%, вторым важным плюсом является возможность в отлавливании причин по которым фото оказалось неподходящим, так после работы программы block 6 мы получили 13 неопознанных фото, из которых одно низкого качества, на пяти фотографиях присутствует несколько человек и на 7 фото нет лиц. То есть используя данную библиотеку мы можем приоткрыть завесу черного ящика и отследить причину по которой фото \"бракуется\". Однако, как и говорилось выше, это накладывает более высокую ответственность на программиста, ведь, если не проявлять должной бдительности при отлове фото, 12 из 13 неопознанных можно было бы пропустить, что могло бы снизить качество разработанного решения и добавить в него неверифицируемых людей, при этом нигде явно об этом не сообщая.\n","* Разработанная в block 6 программа может использоваться в дальнейшем, если не для разбора пола, что она делает с вероятностью меньшей 80%, то для поиска и удаления неподходящих фото - с целью оповестить потенциальных пользователей о необходимости замены их фото на новые.\n","\n","> Block 5 и Block 6 являются не обязательными для запуска и использования программы, но позволяют ознакомиться с результатами проделанных экспериментов. Они работоспособны и могут быть запущенных в общем потоке программы, однако их работа может занять более 5 минут времени.\n","\n","> **Если вас интересуют исключительно результаты работы данных блоков - можно воспользоваться block 4, который загрузит архивы содержащие их в общую папку, откуда вы сможете их сразу загрузить без ожидания их выполнения.**\n","\n","> **В дальнейшей работе программы не будут использоваться те 13 фотографий, которые были определены как не качественные, подобная отчистка хоть и незначильно но позвоялет приблизиться к цели сокращения затрат времени на верификацию человека на видео.**"],"metadata":{"id":"yTZ_sCMMn6EX"}},{"cell_type":"markdown","metadata":{"id":"KKIInXs_VoDO"},"source":["**block 4 (optional):** Загрузка результатов, которые можно получить выполнением block 5 и block 6.:\n","\n",">**Данный блок недоступен для выполнения из-за требований правообладателя, данные испольхуемые в нем изъяты из публичного доступа. Вы можете указать ссылки на свои данные для его использования.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kZS_qQ1SQUx"},"outputs":[],"source":["\"\"\"\n","files_url = {\n","    \"gender_staff_deepface.zip\" : \"\" # Архив результатов для deepface\n","    ,\"gender_staff_insightface.zip\" : \"\" # Архив результатов для insightface\n","    ,\"photo_staff_clean.zip\" : \"\" # Архив отчищенных фото\n","}\n","\n","for file in files_url:\n","  gdown.download(files_url[file], file, quiet=False)\n","\n","# Раскомментировать код внизу, если помимо загрузки нужно распаковать архивы (Нужно для работы block 7)\n","\"\"\"\n","\"\"\"\n","with zipfile.ZipFile('/content/gender_staff_deepface.zip', 'r') as gender1_zip:\n","  gender1_zip.extractall('/')\n","gender1_zip.close()\n","\n","with zipfile.ZipFile('/content/gender_staff_insightface.zip', 'r') as gender2_zip:\n","  gender2_zip.extractall('/')\n","gender2_zip.close()\n","\n","with zipfile.ZipFile('/content/photo_staff_clean.zip', 'r') as gender3_zip:\n","  gender3_zip.extractall('/')\n","gender3_zip.close()\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"69KkeRlmfaTZ"},"source":["**block 5 (optional):** создание папок и сортировка изображений на три группы: man, woman and unrecognized, с использованием библиотеки deepface. Сворачивание результатов работы в zip-архив для извлечения."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_K8KZE0q-xB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712401591762,"user_tz":-180,"elapsed":333219,"user":{"displayName":"Евгений Коровин","userId":"16571264909826974855"}},"outputId":"ded53c48-180d-4aa5-82b6-37a02da92e79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Фото 327_zulip.jpeg не подлежит распознаванию\n","24-04-06 11:01:01 - gender_model_weights.h5 will be downloaded...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://github.com/serengil/deepface_models/releases/download/v1.0/gender_model_weights.h5\n","To: /root/.deepface/weights/gender_model_weights.h5\n","100%|██████████| 537M/537M [00:10<00:00, 50.3MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Фото 235_miem.jpeg не подлежит распознаванию\n","Фото 83_miem.jpeg не подлежит распознаванию\n","Фото 421_miem.jpeg не подлежит распознаванию\n","Фото 345_miem.jpeg не подлежит распознаванию\n","Фото 431_miem.jpeg не подлежит распознаванию\n","Фото 56_miem.jpeg не подлежит распознаванию\n","Фото 488_zulip.jpeg не подлежит распознаванию\n","Фото 388_miem.jpeg не подлежит распознаванию\n","Фото 132_miem.jpeg не подлежит распознаванию\n","Фото 19_zulip.jpeg не подлежит распознаванию\n","Фото 491_zulip.jpeg не подлежит распознаванию\n","Фото 425_miem.jpeg не подлежит распознаванию\n","Фото 134_zulip.jpeg не подлежит распознаванию\n","Фото 360_miem.jpeg не подлежит распознаванию\n","Фото 74_zulip.jpeg не подлежит распознаванию\n","Фото 145_miem.jpeg не подлежит распознаванию\n","Фото 137_miem.jpeg не подлежит распознаванию\n","Фото 368_miem.jpeg не подлежит распознаванию\n","Фото 297_miem.jpeg не подлежит распознаванию\n","Фото 180_miem.jpeg не подлежит распознаванию\n","Фото 294_miem.jpeg не подлежит распознаванию\n","Фото 183_miem.jpeg не подлежит распознаванию\n","Фото 428_miem.jpeg не подлежит распознаванию\n","Фото 456_miem.jpeg не подлежит распознаванию\n","Фото 69_miem.jpeg не подлежит распознаванию\n","Фото 296_miem.jpeg не подлежит распознаванию\n","Фото 61_miem.jpeg не подлежит распознаванию\n","Фото 219_miem.jpeg не подлежит распознаванию\n","Фото 173_miem.jpeg не подлежит распознаванию\n","Фото 277_miem.jpeg не подлежит распознаванию\n","Фото 214_miem.jpeg не подлежит распознаванию\n","Фото 337_miem.jpeg не подлежит распознаванию\n","Фото 22_miem.jpeg не подлежит распознаванию\n","Фото 136_miem.jpeg не подлежит распознаванию\n","Фото 319_miem.jpeg не подлежит распознаванию\n","Фото 245_miem.jpeg не подлежит распознаванию\n","Фото 67_miem.jpeg не подлежит распознаванию\n","Фото 309_miem.jpeg не подлежит распознаванию\n","Фото 343_miem.jpeg не подлежит распознаванию\n","Фото 490_miem.jpeg не подлежит распознаванию\n","Фото 469_miem.jpeg не подлежит распознаванию\n","Фото 47_miem.jpeg не подлежит распознаванию\n","Фото 367_miem.jpeg не подлежит распознаванию\n","Фото 352_miem.jpeg не подлежит распознаванию\n","Фото 63_zulip.jpeg не подлежит распознаванию\n","Фото 216_miem.jpeg не подлежит распознаванию\n","Фото 389_miem.jpeg не подлежит распознаванию\n","Фото 410_miem.jpeg не подлежит распознаванию\n","Фото 341_miem.jpeg не подлежит распознаванию\n","Фото 133_miem.jpeg не подлежит распознаванию\n","Фото 17_zulip.jpeg не подлежит распознаванию\n","Фото 141_miem.jpeg не подлежит распознаванию\n","Фото 229_miem.jpeg не подлежит распознаванию\n","Фото 253_miem.jpeg не подлежит распознаванию\n","Фото 151_miem.jpeg не подлежит распознаванию\n","Фото 344_miem.jpeg не подлежит распознаванию\n","Фото 330_miem.jpeg не подлежит распознаванию\n"]}],"source":["os.makedirs('man_deepface', exist_ok=True)\n","os.makedirs('woman_deepface', exist_ok=True)\n","os.makedirs('unrecognized_deepface', exist_ok=True)\n","\n","dataset_path = os.listdir('photo_staff')\n","zip_deepface = zipfile.ZipFile('/content/gender_staff_deepface.zip', 'w', zipfile.ZIP_DEFLATED)\n","\n","def gender_analyze(img_name):\n","    try:\n","      result = DeepFace.analyze('/content/photo_staff/'+img_name, actions=['gender'])\n","      if result[0]['gender']['Man'] > result[0]['gender']['Woman']:\n","          shutil.copy('/content/photo_staff/'+img_name, '/content/man_deepface')\n","          zip_deepface.write('/content/man_deepface/'+img_name)\n","      else:\n","          shutil.copy('/content/photo_staff/'+img_name, '/content/woman_deepface')\n","          zip_deepface.write('/content/woman_deepface/'+img_name)\n","    except ValueError:\n","      shutil.copy('/content/photo_staff/'+img_name, '/content/unrecognized_deepface')\n","      zip_deepface.write('/content/unrecognized_deepface/'+img_name)\n","      print(f\"Фото {img_name} не подлежит распознаванию\")\n","\n","for image_name in dataset_path:\n","    #print(f\"Начали анализ фото {image_name}\")\n","    #print(f\"Начали анализ фото {'/content/photo_staff/'+image_name}\")\n","    gender_analyze(image_name)\n","zip_deepface.close()\n"]},{"cell_type":"markdown","source":["**block 6 (optional):** создание папок и сортировка изображений на три группы: man, woman and unrecognized, с использованием библиотеки insightface. Сворачивание результатов работы в zip-архив для извлечения. Создание Json файла с эмбедингами фотографий признанных пригодными для работы."],"metadata":{"id":"8wyvf_Ozpn7G"}},{"cell_type":"code","source":["os.makedirs('man_insightface', exist_ok=True)\n","os.makedirs('woman_insightface', exist_ok=True)\n","os.makedirs('unrecognized_insightface', exist_ok=True)\n","\n","os.makedirs('photo_staff_clean', exist_ok=True)\n","emb_staff_dict = {}\n","\n","dataset_path = os.listdir('photo_staff')\n","zip_insightface = zipfile.ZipFile('/content/gender_staff_insightface.zip', 'w', zipfile.ZIP_DEFLATED)\n","zip_clean = zipfile.ZipFile('/content/gender_staff_clean.zip', 'w', zipfile.ZIP_DEFLATED)\n","\n","model_gender = FaceAnalysis(name=\"buffalo_l\")\n","model_gender.prepare(ctx_id=0, det_size=(256,256))\n","\n","def gender_analyze(img_name):\n","    try:\n","      fail = 0\n","      result = model_gender.get(cv2.imread('/content/photo_staff/'+img_name))\n","      if result == []:\n","        fail += 1\n","        shutil.copy('/content/photo_staff/'+img_name, '/content/unrecognized_insightface')\n","        zip_insightface.write('/content/unrecognized_insightface/'+img_name)\n","        zip_clean.write('/content/unrecognized_insightface/'+img_name)\n","        print(f\"Фото {img_name} не подлежит распознаванию - не найдено лицо\")\n","        return 0\n","      if len(result) != 1 and fail == 0:\n","        fail += 1\n","        shutil.copy('/content/photo_staff/'+img_name, '/content/unrecognized_insightface')\n","        zip_insightface.write('/content/unrecognized_insightface/'+img_name)\n","        zip_clean.write('/content/unrecognized_insightface/'+img_name)\n","        print(f\"Фото {img_name} не подлежит распознаванию - найдено более одного лица\")\n","        return 3\n","      #print(result)\n","      #print(\"\")\n","      if fail == 0:\n","        for face in result:\n","          result_gender = face.gender\n","          emb_staff_dict[img_name] = (face.embedding).tolist()\n","          #print(f\"Фото {img_name} номер пола {result_gender}\")\n","          if result_gender == 1:\n","              shutil.copy('/content/photo_staff/'+img_name, '/content/man_insightface')\n","              shutil.copy('/content/photo_staff/'+img_name, '/content/photo_staff_clean')\n","              zip_insightface.write('/content/man_insightface/'+img_name)\n","              zip_clean.write('/content/photo_staff_clean/'+img_name)\n","          else:\n","              shutil.copy('/content/photo_staff/'+img_name, '/content/woman_insightface')\n","              shutil.copy('/content/photo_staff/'+img_name, '/content/photo_staff_clean')\n","              zip_insightface.write('/content/woman_insightface/'+img_name)\n","              zip_clean.write('/content/photo_staff_clean/'+img_name)\n","        return 1\n","    except AttributeError:\n","      shutil.copy('/content/photo_staff/'+img_name, '/content/unrecognized_insightface')\n","      zip_insightface.write('/content/unrecognized_insightface/'+img_name)\n","      zip_clean.write('/content/unrecognized_insightface/'+img_name)\n","      print(f\"Фото {img_name} не подлежит распознаванию - качество фото (AttError)\")\n","      return 2\n","\n","for image_name in dataset_path:\n","    #print(f\"Начали анализ фото {image_name}\")\n","    #print(f\"Начали анализ фото {'/content/photo_staff/'+image_name}\")\n","    def_state = gender_analyze(image_name)\n","    if def_state != 1:\n","      print(def_state)\n","with open('emb_staff_dict.json', 'w') as f:\n","    json.dump(emb_staff_dict, f)\n","zip_insightface.close()\n","zip_clean.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TToXh2uvTCfl","executionInfo":{"status":"ok","timestamp":1712401920999,"user_tz":-180,"elapsed":329250,"user":{"displayName":"Евгений Коровин","userId":"16571264909826974855"}},"outputId":"c53cec78-4565-4ea5-c2e8-d7433dda7c2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["download_path: /root/.insightface/models/buffalo_l\n","Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 281857/281857 [00:04<00:00, 60573.35KB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n","Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n","Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n","Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n","Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n","set det-size: (256, 256)\n","Фото 327_zulip.jpeg не подлежит распознаванию - не найдено лицо\n","0\n","Фото 345_miem.jpeg не подлежит распознаванию - не найдено лицо\n","0\n","Фото 263_miem.jpeg не подлежит распознаванию - найдено более одного лица\n","3\n","Фото 19_zulip.jpeg не подлежит распознаванию - не найдено лицо\n","0\n","Фото 15_miem.jpeg не подлежит распознаванию - найдено более одного лица\n","3\n","Фото 74_zulip.jpeg не подлежит распознаванию - не найдено лицо\n","0\n","Фото 337_miem.jpeg не подлежит распознаванию - не найдено лицо\n","0\n","Фото 178_miem.jpeg не подлежит распознаванию - найдено более одного лица\n","3\n","Фото 63_zulip.jpeg не подлежит распознаванию - не найдено лицо\n","0\n","Фото 216_miem.jpeg не подлежит распознаванию - найдено более одного лица\n","3\n","Фото 389_miem.jpeg не подлежит распознаванию - качество фото (AttError)\n","2\n","Фото 282_miem.jpeg не подлежит распознаванию - найдено более одного лица\n","3\n","Фото 330_miem.jpeg не подлежит распознаванию - не найдено лицо\n","0\n"]}]},{"cell_type":"markdown","metadata":{"id":"2zM-T3HixsGH"},"source":["**block 7 (optional):** Подсчет количества изображений в разных папках.\n","> В данном блоке можно ознакомиться с результатами разных библиотек на представленном списке фотографий. Данные показатели могут использоваться для оценки эффективности решений или определения иных статистических показателей.\n","\n","> **Данный блок не будет работать, если не запустить block 4 или совместно block 5 и block 6.**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1712401920999,"user":{"displayName":"Евгений Коровин","userId":"16571264909826974855"},"user_tz":-180},"id":"_KYquzO3tTz-","outputId":"c218b83e-4fcf-417c-ba7f-552789c5c87d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Количество файлов папке /content/photo_staff: 464\n","\n","Количество файлов папке /content/woman_deepface: 74\n","Количество файлов папке /content/woman_insightface: 123\n","\n","Количество файлов папке /content/man_deepface: 332\n","Количество файлов папке /content/man_insightface: 328\n","\n","Количество файлов папке /content/unrecognized_deepface: 58\n","Количество файлов папке /content/unrecognized_insightface: 13\n","\n","Количество файлов в папке /content/photo_staff_clean: 451\n","\n","Количество файлов в clean архиве: 464\n","Количество файлов в deepface папках: 464\n","Количество файлов в insightface папках: 464\n"]}],"source":["folder_path_list = ['/content/woman', '/content/man', '/content/unrecognized']\n","file_add_deepface = 0 # Инициализируем переменные для хранения сумм файлов\n","file_add_insightface = 0\n","file_add_clean = 0\n","file_count_clean = 0\n","file_unrecognized_insightface = 0\n","\n","file_count_base = 0 # Инициализируем счетчик файлов исходной папки\n","\n","for root, dirs, files in os.walk('/content/photo_staff'):\n","  file_count_base += len(files)\n","print(f\"Количество файлов папке {'/content/photo_staff'}: {file_count_base}\\n\")\n","\n","for folder_path in folder_path_list:\n","  file_count_deepface = 0 # Инициализируем счетчики файлов\n","  file_count_insightface = 0\n","\n","  for root, dirs, files in os.walk(folder_path+'_deepface'): # Осуществляем обход всех элементов папки\n","      file_count_deepface += len(files) # Для каждого файла увеличиваем счетчик\n","\n","  for root, dirs, files in os.walk(folder_path+'_insightface'):\n","      file_count_insightface += len(files)\n","\n","  print(f\"Количество файлов папке {folder_path+'_deepface'}: {file_count_deepface}\")\n","  print(f\"Количество файлов папке {folder_path+'_insightface'}: {file_count_insightface}\\n\")\n","\n","  file_unrecognized_insightface = file_count_insightface\n","\n","  file_add_deepface += file_count_deepface\n","  file_add_insightface += file_count_insightface\n","\n","for root, dirs, files in os.walk(\"/content/photo_staff_clean\"):\n","    file_count_clean += len(files)\n","print(f\"Количество файлов в папке /content/photo_staff_clean: {file_count_clean}\\n\")\n","\n","print(f\"Количество файлов в clean архиве: {file_count_clean + file_unrecognized_insightface}\")\n","print(f\"Количество файлов в deepface папках: {file_add_deepface}\")\n","print(f\"Количество файлов в insightface папках: {file_add_insightface}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P1CLCzUyUnlL"},"source":["**block 8:**\n","> В данном блоке задаем основные зависящие от нас параметры обработки видео: frame_start, step and videos.\n","*   frame_start - стартовый фрейм с которого начинается осмотр видео (по умолчанию поставлен 0);\n","*   step - шаг разбиения, количество фреймов из видео, которые мы будем анализировать (анализ каждого кадра видео потребует слишком многого процессорного времени, от того было решено - выбрать некоторое количество\n","кадров, через равные по размеру промежутки, тем самым охватив все видео)\n","*   videos - список, в котором нужно указать наименования загруженных видео-файлов, которые подлежат анализу. По умолчанию указаны загруженные выше видео;\n","* Происходит загрузка Json-файла с эмбедингами лиц преподавателей, которых собираемся искать на видео;\n","* found_photo_dict - словарь, для хранения найденных лиц в видео в форме {фотография : количество обнаружений}.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sS2DbdZ-VML7"},"outputs":[],"source":["emb_staff_dict = {}\n","\n","with open('emb_staff_dict.json', 'r') as f:\n","    emb_staff_dict = json.load(f)\n","for key, value in emb_staff_dict.items():\n","  emb_staff_dict[key] = np.array(value)\n","\n","videos = [\"video1.mp4\", \"video2.mp4\", \"video3.mp4\"] # Список загруженных для анализа видео\n","frame_start = 0 # стартовый фрейм\n","step = 400 # Количетсво кадров видео, которые будут осмотрены (из-за особенностей реализации, почти всегда будет на 1 кадр меньше)\n","found_photo_dict = {}\n","\n","def AddPhotoToDict(key): # Функция добавляет в словарь информацию о найденных лицах\n","  if found_photo_dict.get(key) is not None:\n","    found_photo_dict[key] += 1\n","  else:\n","    found_photo_dict[key] = 1"]},{"cell_type":"markdown","metadata":{"id":"ZiCdOg_xfSrH"},"source":["**block 9:** Анализ видеопотока, проведение верефикации и вывод рехультатов."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKJv2GL6x4AE","outputId":"4b186bd8-d30f-4fe4-de7f-5bb68d1750d1","executionInfo":{"status":"ok","timestamp":1712411948575,"user_tz":-180,"elapsed":1861793,"user":{"displayName":"Евгений Коровин","userId":"16571264909826974855"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n","Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n","Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n","Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n","Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n","find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n","set det-size: (256, 256)\n","\n","Началась обработка видео: video1.mp4\n","Всего кадров в video1.mp4: 48082\n","На видео video1.mp4 потенциально могут присутствовать:\n","человек с фото 425_miem.jpeg, а именно Хокшанов Наран Саналович\n","человек с фото 335_miem.jpeg, а именно Крупицын Евгений Станиславович\n","человек с фото 357_miem.jpeg, а именно Каган Максим Юрьевич\n","человек с фото 70_miem.jpeg, а именно Арутюнов Константин Юрьевич\n","{'425_miem.jpeg': 3, '335_miem.jpeg': 3, '357_miem.jpeg': 2, '70_miem.jpeg': 3, '21_zulip.jpeg': 1, '421_miem.jpeg': 1, '9_zulip.jpeg': 1}\n","\n","Началась обработка видео: video2.mp4\n","Всего кадров в video2.mp4: 132772\n","На видео video2.mp4 потенциально могут присутствовать:\n","человек с фото 425_miem.jpeg, а именно Хокшанов Наран Саналович\n","человек с фото 335_miem.jpeg, а именно Крупицын Евгений Станиславович\n","человек с фото 70_miem.jpeg, а именно Арутюнов Константин Юрьевич\n","{'425_miem.jpeg': 14, '402_miem.jpeg': 1, '335_miem.jpeg': 2, '70_miem.jpeg': 2, '21_zulip.jpeg': 1, '341_miem.jpeg': 1}\n","\n","Началась обработка видео: video3.mp4\n","Всего кадров в video3.mp4: 133273\n","На видео video3.mp4 потенциально могут присутствовать:\n","человек с фото 425_miem.jpeg, а именно Хокшанов Наран Саналович\n","человек с фото 182_miem.jpeg, а именно Попов Дмитрий Александрович\n","{'425_miem.jpeg': 14, '357_miem.jpeg': 1, '70_miem.jpeg': 1, '182_miem.jpeg': 2, '182_zulip.jpeg': 1}\n"]}],"source":["model = FaceAnalysis(name=\"buffalo_l\")\n","model.prepare(ctx_id=0, det_size=(256,256))\n","\n","for video_now in videos:\n","\n","  frame_now = frame_start\n","  cap = cv2.VideoCapture('/content/'+video_now)\n","  size_cap = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","  step_cap = int(size_cap / step) # размер шага (на сколько делим число кадров, столько кадров и возьмем для анализа)\n","  print(f\"\\nНачалась обработка видео: {video_now}\")\n","  print(f\"Всего кадров в {video_now}:\", size_cap)\n","\n","  while(size_cap > frame_now):\n","    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_now)\n","    ret, frame = cap.read()\n","    if ret:\n","      #cv2.imshow('Frame', frame) # не работает в гугл колаб, ниже реализована замена специально под него\n","      #print(\"Это кадр №\", frame_now)\n","      #cv2_imshow(frame) # выводит на экран выбранный в данный момент кадр видео\n","      #cv2.waitKey(0)    # Показывает этот кадр пока не нажата любая клавиша (в гугл колаб - просто показывает кадр)\n","      #print('\\n')\n","      faces = model.get(frame)\n","      if (faces != []):\n","        for face in faces:\n","          face_emb = face.embedding\n","          for key in emb_staff_dict:\n","            #print(face_emb)\n","            distance = np.linalg.norm(emb_staff_dict[key] - face_emb)\n","            #print(key, distance)\n","            threshold = 20 # можно менять, в случае, если находится слишком много совпадений\n","            if distance < threshold:\n","              AddPhotoToDict(key)\n","              #print(face_emb)\n","              #cv2_imshow(frame)\n","              #bbox = face.bbox\n","              #print(face.bbox)\n","              #cv2_imshow(frame[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])])\n","    else:\n","      print(\"Не удалось прочитать кадр\")\n","    frame_now = frame_now + step_cap\n","  if len(found_photo_dict) != 0:\n","    first_true_detect = 0\n","    for key in found_photo_dict:\n","      if found_photo_dict[key] > 1 and first_true_detect == 0:\n","        data = pd.read_csv('names.csv')\n","        first_true_detect = 1\n","        print(f\"На видео {video_now} потенциально могут присутствовать:\")\n","        for index, row in data.iterrows():\n","          if row[4] == key:\n","            print(f\"человек с фото {row[4]}, а именно {row[1]}\")\n","      elif found_photo_dict[key] > 1:\n","        for index, row in data.iterrows():\n","          if row[4] == key:\n","            print(f\"человек с фото {row[4]}, а именно {row[1]}\")\n","    if (first_true_detect == 0):\n","      print(f\"На видео {video_now} никого не удалось обнаружить.\")\n","  else:\n","    print(f\"На видео {video_now} никого не удалось обнаружить.\")\n","  print(found_photo_dict)\n","  found_photo_dict = {}"]},{"cell_type":"markdown","source":["# **Results:**\n",">**Результаты проделанной работы не позволяют однозначно говорить о потенциале применения бибилоитек deepface и insightface в задаче верификации челвоека на видео. Поскольку основной вопрос справедливости оценивания замыкается на качестве исходных данных, а именно, на качестве изображений верифицируемых людей.**\n","\n","Общией рекомендацией для осуществления дальнейших работ может являться:\n","\n","* Повышение качества используемых материалов;\n","* Контроль за соответствием фотографии разыскиваемого пользователя его реальному виду;\n","* Повышение требований к разрешению фотографий и ограничение использования фотографий в оттенках серого;\n","* Повышение качества средств сбора видеопотока.\n","\n","\n"],"metadata":{"id":"Ae2GCzv3tmta"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1fmoHQW9Ux5rW9etOZUnU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}